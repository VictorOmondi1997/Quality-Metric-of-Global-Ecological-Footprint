{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the Quality Metric of Global Ecological Footprint\n",
    "\n",
    "> Managing the Quality Metric of Global Ecological Footprint\n",
    "\n",
    "- author: Victor Omondi\n",
    "- toc: true\n",
    "- comments: true\n",
    "- categories: [classification, machine-learning]\n",
    "- image: images/mqmgef-shield.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Machine Learning: Classification - Managing the Quality Metric of Global Ecological Footprint\n",
    "\n",
    "\n",
    "The dataset used  was obtained from the National Footprint and Biocapacity Accounts. It provides Ecological Footprint per capita data for years 1961-2016 in global hectares (gha). The National Footprint and Biocapacity Accounts (NFAs) measure the ecological resource use and resource capacity of nations from 1961 to 2016. The calculations in the National Footprint and Biocapacity Accounts are primarily based on United Nations data sets.\n",
    "\n",
    "We will use the data to classify and predict the quality metrics (qascore) of the ecological footprint data for the different countries. This data includes total and per capita national biocapacity, the ecological footprint of consumption, the ecological footprint of production and total area in hectares.\n",
    "\n",
    "Data Source: https://data.world/footprint/nfa-2019-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import (LabelEncoder, \n",
    "                                   MinMaxScaler)\n",
    "from sklearn.model_selection import (cross_val_score, \n",
    "                                     KFold, \n",
    "                                     LeaveOneOut, \n",
    "                                     StratifiedKFold, \n",
    "                                     train_test_split)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix, \n",
    "                             f1_score, \n",
    "                             precision_score, \n",
    "                             recall_score)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will Explore linear classification.\n",
    "\n",
    "In machine learning, classification is a supervised method of segmenting data points into various labels or classes. Unlike regression, the target variable in a classification problem is discrete. Each data point used in training classification models must have a corresponding label in order for the characteristics and patterns in the classes to be learnt appropriately. Classification can either be binary - identifying that a given email is spam or not or, multi-class - classifying a fruit as orange, mango or banana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every year people demand more from nature than it can regenerate. Individuals, communities and government leaders use ecological footprint data to better manage limited resources, reduce economic risk, and improve well-being. The Dataset provides Ecological Footprint per capita data for years 1961-2016 in global hectares (gha). Ecological Footprint is a measure of how much area of biologically productive land and water an individual, population, or activity requires to produce all the resources it consumes and to absorb the waste it generates, using prevailing technology and resource management practices. The Ecological Footprint is measured in global hectares. Since trade is global, an individual or country's Footprint tracks area from all over the world. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from predicting numeric values, another important supervised machine learning method is classification and it involves predicting classes (either binary or multinomial classes). In this section, we will cover how to measure performances of class prediction, linear classification methods and non-linear/tree-based methods. Weâ€™ll also focus on strategies for applying a successful classification model like interpretability-accuracy trade-off, class and imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The National Footprint and Biocapacity Accounts (NFAs) measure the ecological resource use and resource capacity of nations from 1961 to 2016. The calculations in the National Footprint and Biocapacity Accounts are primarily based on United Nations data sets, including those published by the Food and Agriculture Organization, United Nations Commodity Trade Statistics Database, and the UN Statistics Division, as well as the International Energy Agency. In this project, we will use this data to classify and predict the quality metrics (qascore) of the ecological footprint data for the different countries. This data includes total and per capita national biocapacity, the ecological footprint of consumption, the ecological footprint of production and total area in hectares.\n",
    "\n",
    "Data Source: https://data.world/footprint/nfa-2019-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, classification is a supervised method of segmenting data points into various labels or classes. Unlike regression, the target variable in a classification problem is discrete. Each data point used in training classification models must have a corresponding label in order for the characteristics and patterns in the classes to be learnt appropriately. Classification can either be binary - identifying that a given email is spam or not or, multi-class - classifying a fruit as orange, mango or banana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear classifiers and the importance of class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we define a linear classifier as a binary classifier that separates two classes (positive and negative class) using a linear separator by computing a linear combination of the features and comparing against a set threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Sigmoid, logit and the log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a linear algorithm that can be used for binary or multiclass classification. It is a discriminative classifier that estimates the probability that an instance belongs to a class using an s-shape function curve called the sigmoid function. The predicted values obtained after using a linear equation on the predictors by applying logistic regression can fall in the range of negative infinity to positive infinity. The sigmoid maps these results by shrinking the value to fall between 0 and 1.  We can say that we use the sigmoid function to transform linear regression into logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "sigmoid\\ \\sigma \\ (x) = \\frac{1}{1+e^{-x}} \n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](datasets/images/sigmoid-curve.png \"sigmoid-curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function can be applied to a linear equation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z = \\beta_0 + \\beta_{1}x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to obtain values h between 0 and 1 such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h = \\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{1}{1 + e^{-{\\beta_0 + \\beta_{1}x}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a binary classification task with classes A and B, if a threshold is set for 0.5 and the probability of an instance belonging to a class is $p$, we can say that if $p < 0.5$ the instance if of class A while it is of class B is $p > 0.5$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as the log of odds, logit is the logarithm of odds ratio where the odds ratio is the probability that an event occurs divided by the probability that the event does not occur. Logit is the inverse of the sigmoid such that it maps values from negative infinity to positive infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log{it}(p) = \\log(\\frac{p}{1 - p})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Recall that in linear regression, we minimized the sum of squared errors SSE; in logistic regression, the log-likelihood is maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.097188051</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.032351e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>483000.000000</td>\n",
       "      <td>687000.000000</td>\n",
       "      <td>334600</td>\n",
       "      <td>127000.000000</td>\n",
       "      <td>100943.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732543e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.135261</td>\n",
       "      <td>0.084003213</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.262086e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>550176.242700</td>\n",
       "      <td>465677.972200</td>\n",
       "      <td>289207.1078</td>\n",
       "      <td>47311.551720</td>\n",
       "      <td>114982.279300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467355e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>1.26E-06</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>1.114093</td>\n",
       "      <td>1.728629e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year  country_code        record      crop_land   grazing_land  \\\n",
       "0  Armenia  1992             1    AreaPerCap       0.140292       0.199546   \n",
       "1  Armenia  1992             1     AreaTotHA  483000.000000  687000.000000   \n",
       "2  Armenia  1992             1  BiocapPerCap       0.159804       0.135261   \n",
       "3  Armenia  1992             1  BiocapTotGHA  550176.242700  465677.972200   \n",
       "4  Armenia  1992             1  EFConsPerCap       0.387510       0.189462   \n",
       "\n",
       "   forest_land  fishing_ground  built_up_land    carbon         total QScore  \n",
       "0  0.097188051        0.036888       0.029320  0.000000  5.032351e-01     3A  \n",
       "1       334600   127000.000000  100943.000800  0.000000  1.732543e+06     3A  \n",
       "2  0.084003213        0.013742       0.033398  0.000000  4.262086e-01     3A  \n",
       "3  289207.1078    47311.551720  114982.279300  0.000000  1.467355e+06     3A  \n",
       "4     1.26E-06        0.004165       0.033398  1.114093  1.728629e+00     3A  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/raw/NFA 2019 public_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72186 entries, 0 to 72185\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   country         72186 non-null  object \n",
      " 1   year            72186 non-null  int64  \n",
      " 2   country_code    72186 non-null  int64  \n",
      " 3   record          72186 non-null  object \n",
      " 4   crop_land       51714 non-null  float64\n",
      " 5   grazing_land    51714 non-null  float64\n",
      " 6   forest_land     51714 non-null  object \n",
      " 7   fishing_ground  51713 non-null  float64\n",
      " 8   built_up_land   51713 non-null  float64\n",
      " 9   carbon          51713 non-null  float64\n",
      " 10  total           72177 non-null  float64\n",
      " 11  QScore          72185 non-null  object \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country               0\n",
       "year                  0\n",
       "country_code          0\n",
       "record                0\n",
       "crop_land         20472\n",
       "grazing_land      20472\n",
       "forest_land       20472\n",
       "fishing_ground    20473\n",
       "built_up_land     20473\n",
       "carbon            20473\n",
       "total                 9\n",
       "QScore                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has a lot of missing values from `crop_land:carbon` columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51481\n",
       "2A    10576\n",
       "2B    10096\n",
       "1B       16\n",
       "1A       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "For simplicity, we will drop the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           0\n",
       "year              0\n",
       "country_code      0\n",
       "record            0\n",
       "crop_land         0\n",
       "grazing_land      0\n",
       "forest_land       0\n",
       "fishing_ground    0\n",
       "built_up_land     0\n",
       "carbon            0\n",
       "total             0\n",
       "QScore            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      224\n",
       "1A       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An obvious change in our target variable after removing the missing values is that there are only three classes left. From the distribution of the 3 classes, we can see that there is an obvious imbalance between the classes. There are methods that can be applied to handle this imbalance such as oversampling and undersampling.\n",
    "\n",
    "- Oversampling involves increasing the number of instances in the class with fewer instances\n",
    "- Undersampling involves reducing the data points in the class with more instances.\n",
    "For now, we will convert this to a binary classification problem by combining class '2A' and '1A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['QScore'] = df.QScore.replace(['1A'], '2A')\n",
    "df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19172</th>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>2016</td>\n",
       "      <td>61</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>2.113976e-01</td>\n",
       "      <td>2.680246e-02</td>\n",
       "      <td>0.165406213</td>\n",
       "      <td>8.998100e-02</td>\n",
       "      <td>2.247772e-02</td>\n",
       "      <td>1.359850e+00</td>\n",
       "      <td>1.875915e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42455</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>2016</td>\n",
       "      <td>143</td>\n",
       "      <td>EFProdTotGHA</td>\n",
       "      <td>8.723089e+06</td>\n",
       "      <td>5.623982e+06</td>\n",
       "      <td>2861022.894</td>\n",
       "      <td>4.989264e+06</td>\n",
       "      <td>9.241300e+05</td>\n",
       "      <td>2.057104e+07</td>\n",
       "      <td>4.369253e+07</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61614</th>\n",
       "      <td>Togo</td>\n",
       "      <td>1996</td>\n",
       "      <td>217</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>3.370050e-01</td>\n",
       "      <td>7.458356e-02</td>\n",
       "      <td>0.511850313</td>\n",
       "      <td>8.418123e-02</td>\n",
       "      <td>1.916901e-02</td>\n",
       "      <td>1.200963e-01</td>\n",
       "      <td>1.146885e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62670</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>4.275409e-01</td>\n",
       "      <td>1.918018e-01</td>\n",
       "      <td>0.302139636</td>\n",
       "      <td>1.047238e-01</td>\n",
       "      <td>1.222536e-03</td>\n",
       "      <td>7.350750e+00</td>\n",
       "      <td>8.378179e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22016</th>\n",
       "      <td>Djibouti</td>\n",
       "      <td>2016</td>\n",
       "      <td>72</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>2.122392e-03</td>\n",
       "      <td>1.804033e+00</td>\n",
       "      <td>0.005942697</td>\n",
       "      <td>2.446057e-01</td>\n",
       "      <td>2.647769e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.083182e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15481</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>2016</td>\n",
       "      <td>52</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>2.240000e+06</td>\n",
       "      <td>2.533000e+06</td>\n",
       "      <td>1165620</td>\n",
       "      <td>3.930000e+05</td>\n",
       "      <td>3.005230e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.632143e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63815</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>2014</td>\n",
       "      <td>223</td>\n",
       "      <td>EFConsTotGHA</td>\n",
       "      <td>6.480075e+07</td>\n",
       "      <td>7.677842e+06</td>\n",
       "      <td>25286823.19</td>\n",
       "      <td>2.289002e+06</td>\n",
       "      <td>2.594082e+06</td>\n",
       "      <td>1.484026e+08</td>\n",
       "      <td>2.510511e+08</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62673</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>EFProdTotGHA</td>\n",
       "      <td>6.071428e+04</td>\n",
       "      <td>8.287973e+03</td>\n",
       "      <td>129192.8608</td>\n",
       "      <td>8.413697e+04</td>\n",
       "      <td>1.668713e+03</td>\n",
       "      <td>1.216205e+07</td>\n",
       "      <td>1.244605e+07</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57336</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>2016</td>\n",
       "      <td>202</td>\n",
       "      <td>EFProdPerCap</td>\n",
       "      <td>2.073526e-01</td>\n",
       "      <td>1.934319e-01</td>\n",
       "      <td>0.26312955</td>\n",
       "      <td>8.346993e-02</td>\n",
       "      <td>2.523715e-02</td>\n",
       "      <td>2.609595e+00</td>\n",
       "      <td>3.382216e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14319</th>\n",
       "      <td>Cuba</td>\n",
       "      <td>1979</td>\n",
       "      <td>49</td>\n",
       "      <td>EFProdTotGHA</td>\n",
       "      <td>3.786266e+06</td>\n",
       "      <td>9.759010e+05</td>\n",
       "      <td>1343688.028</td>\n",
       "      <td>1.019392e+06</td>\n",
       "      <td>3.434420e+05</td>\n",
       "      <td>1.131251e+07</td>\n",
       "      <td>1.878120e+07</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country  year  country_code        record     crop_land  \\\n",
       "19172    Equatorial Guinea  2016            61  EFConsPerCap  2.113976e-01   \n",
       "42455              Morocco  2016           143  EFProdTotGHA  8.723089e+06   \n",
       "61614                 Togo  1996           217  EFConsPerCap  3.370050e-01   \n",
       "62670  Trinidad and Tobago  2016           220  EFConsPerCap  4.275409e-01   \n",
       "22016             Djibouti  2016            72    AreaPerCap  2.122392e-03   \n",
       "15481           Azerbaijan  2016            52     AreaTotHA  2.240000e+06   \n",
       "63815               Turkey  2014           223  EFConsTotGHA  6.480075e+07   \n",
       "62673  Trinidad and Tobago  2016           220  EFProdTotGHA  6.071428e+04   \n",
       "57336         South Africa  2016           202  EFProdPerCap  2.073526e-01   \n",
       "14319                 Cuba  1979            49  EFProdTotGHA  3.786266e+06   \n",
       "\n",
       "       grazing_land  forest_land  fishing_ground  built_up_land        carbon  \\\n",
       "19172  2.680246e-02  0.165406213    8.998100e-02   2.247772e-02  1.359850e+00   \n",
       "42455  5.623982e+06  2861022.894    4.989264e+06   9.241300e+05  2.057104e+07   \n",
       "61614  7.458356e-02  0.511850313    8.418123e-02   1.916901e-02  1.200963e-01   \n",
       "62670  1.918018e-01  0.302139636    1.047238e-01   1.222536e-03  7.350750e+00   \n",
       "22016  1.804033e+00  0.005942697    2.446057e-01   2.647769e-02  0.000000e+00   \n",
       "15481  2.533000e+06      1165620    3.930000e+05   3.005230e+05  0.000000e+00   \n",
       "63815  7.677842e+06  25286823.19    2.289002e+06   2.594082e+06  1.484026e+08   \n",
       "62673  8.287973e+03  129192.8608    8.413697e+04   1.668713e+03  1.216205e+07   \n",
       "57336  1.934319e-01   0.26312955    8.346993e-02   2.523715e-02  2.609595e+00   \n",
       "14319  9.759010e+05  1343688.028    1.019392e+06   3.434420e+05  1.131251e+07   \n",
       "\n",
       "              total QScore  \n",
       "19172  1.875915e+00     2A  \n",
       "42455  4.369253e+07     2A  \n",
       "61614  1.146885e+00     3A  \n",
       "62670  8.378179e+00     2A  \n",
       "22016  2.083182e+00     2A  \n",
       "15481  6.632143e+06     3A  \n",
       "63815  2.510511e+08     3A  \n",
       "62673  1.244605e+07     2A  \n",
       "57336  3.382216e+00     2A  \n",
       "14319  1.878120e+07     3A  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2A = df[df.QScore=='2A']\n",
    "df_3A = df[df.QScore=='3A'].sample(350)\n",
    "data_df = df_2A.append(df_3A)\n",
    "data_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = shuffle(data_df)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    350\n",
       "2A    240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.QScore.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(columns=['country_code', 'country', 'year'])\n",
    "X = data_df.drop(columns='QScore')\n",
    "y = data_df['QScore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    248\n",
       "2A    165\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still an imbalance in the class distribution. For this, we use SMOTE only on the training data to handle this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "X_train['record'] = encoder.fit_transform(X_train.record)\n",
    "X_test['record'] = encoder.fit_transform(X_test.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=1)\n",
    "X_train_balanced, y_balanced = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.403662e-03</td>\n",
       "      <td>9.455794e-04</td>\n",
       "      <td>7.306580e-03</td>\n",
       "      <td>6.338967e-03</td>\n",
       "      <td>2.896524e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.311340e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.171136e-04</td>\n",
       "      <td>3.115198e-04</td>\n",
       "      <td>2.184420e-05</td>\n",
       "      <td>2.705514e-05</td>\n",
       "      <td>9.561281e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.558996e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.747294e-04</td>\n",
       "      <td>5.145269e-04</td>\n",
       "      <td>2.713808e-05</td>\n",
       "      <td>3.013558e-04</td>\n",
       "      <td>5.157063e-03</td>\n",
       "      <td>2.879969e-02</td>\n",
       "      <td>1.600361e-02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.246356e-10</td>\n",
       "      <td>6.907430e-12</td>\n",
       "      <td>3.324145e-11</td>\n",
       "      <td>4.108555e-10</td>\n",
       "      <td>1.122788e-09</td>\n",
       "      <td>3.100424e-11</td>\n",
       "      <td>1.705827e-10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.040465e-10</td>\n",
       "      <td>5.473459e-11</td>\n",
       "      <td>8.728030e-11</td>\n",
       "      <td>2.364081e-12</td>\n",
       "      <td>1.389536e-10</td>\n",
       "      <td>1.330914e-10</td>\n",
       "      <td>1.414858e-10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crop_land  grazing_land   forest_land  fishing_ground  built_up_land  \\\n",
       "0  1.403662e-03  9.455794e-04  7.306580e-03    6.338967e-03   2.896524e-03   \n",
       "1  7.171136e-04  3.115198e-04  2.184420e-05    2.705514e-05   9.561281e-04   \n",
       "2  7.747294e-04  5.145269e-04  2.713808e-05    3.013558e-04   5.157063e-03   \n",
       "3  2.246356e-10  6.907430e-12  3.324145e-11    4.108555e-10   1.122788e-09   \n",
       "4  2.040465e-10  5.473459e-11  8.728030e-11    2.364081e-12   1.389536e-10   \n",
       "\n",
       "         carbon         total  record  \n",
       "0  0.000000e+00  4.311340e-03       1  \n",
       "1  0.000000e+00  2.558996e-04       3  \n",
       "2  2.879969e-02  1.600361e-02       7  \n",
       "3  3.100424e-11  1.705827e-10       4  \n",
       "4  1.330914e-10  1.414858e-10       4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "normalised_train_df = scaler.fit_transform(X_train_balanced.drop(columns=['record']))\n",
    "normalised_train_df = pd.DataFrame(normalised_train_df, columns=X_train_balanced.drop(columns=['record']).columns)\n",
    "normalised_train_df['record'] = X_train_balanced.record\n",
    "normalised_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.219728e-10</td>\n",
       "      <td>1.365066e-11</td>\n",
       "      <td>2.513993e-10</td>\n",
       "      <td>4.729084e-11</td>\n",
       "      <td>1.595866e-10</td>\n",
       "      <td>1.712429e-10</td>\n",
       "      <td>1.692207e-10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.794621e-11</td>\n",
       "      <td>2.093708e-10</td>\n",
       "      <td>1.893583e-10</td>\n",
       "      <td>3.381674e-10</td>\n",
       "      <td>6.695475e-11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.148909e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.701673e-04</td>\n",
       "      <td>5.205637e-03</td>\n",
       "      <td>4.199154e-03</td>\n",
       "      <td>4.157862e-03</td>\n",
       "      <td>1.223763e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.094954e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.426252e-04</td>\n",
       "      <td>1.505536e-03</td>\n",
       "      <td>2.635490e-03</td>\n",
       "      <td>3.494542e-04</td>\n",
       "      <td>5.976756e-04</td>\n",
       "      <td>4.058477e-05</td>\n",
       "      <td>5.527608e-04</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.465349e-04</td>\n",
       "      <td>6.742536e-04</td>\n",
       "      <td>1.152870e-03</td>\n",
       "      <td>1.089355e-03</td>\n",
       "      <td>9.933233e-04</td>\n",
       "      <td>5.395759e-05</td>\n",
       "      <td>4.245477e-04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crop_land  grazing_land   forest_land  fishing_ground  built_up_land  \\\n",
       "0  2.219728e-10  1.365066e-11  2.513993e-10    4.729084e-11   1.595866e-10   \n",
       "1  6.794621e-11  2.093708e-10  1.893583e-10    3.381674e-10   6.695475e-11   \n",
       "2  9.701673e-04  5.205637e-03  4.199154e-03    4.157862e-03   1.223763e-03   \n",
       "3  7.426252e-04  1.505536e-03  2.635490e-03    3.494542e-04   5.976756e-04   \n",
       "4  9.465349e-04  6.742536e-04  1.152870e-03    1.089355e-03   9.933233e-04   \n",
       "\n",
       "         carbon         total  record  \n",
       "0  1.712429e-10  1.692207e-10       4  \n",
       "1  0.000000e+00  5.148909e-11       0  \n",
       "2  0.000000e+00  1.094954e-03       1  \n",
       "3  4.058477e-05  5.527608e-04       7  \n",
       "4  5.395759e-05  4.245477e-04       5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "normalised_test_df = scaler.fit_transform(X_test.drop(columns=['record']))\n",
    "normalised_test_df = pd.DataFrame(normalised_test_df, columns=X_test.drop(columns=['record']).columns)\n",
    "normalised_test_df['record'] = X_test.record\n",
    "normalised_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(normalised_train_df, y_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Classification Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore cross validation techniques used by data scientist to avoid overfitting and enable generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation (CV) is a well known and trusted method applied to avoid overfitting and enable generalization. Although there are different techniques used in performing cross validation, the fundamental concept involves partitioning the dataset into a number of subsets, holding out a set for evaluation then training the model on the other sets. This gives a more reliable estimate of how the model performs across different training sets because it provides an average score across different training samples used. The only drawback with cross validation is that it takes more time and computational resources however, the gain obtained in having a better model is very well worth this cost. **K-Fold cross validation**, **Stratified K-Fold cross validation** and **Leave One Out Cross Validation (LOOCV)** are some cross validation techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.549955  , 0.47469388, 0.5437788 , 0.5555102 , 0.53301887])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(log_reg, normalised_train_df, y_balanced, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is called K-Fold because the data is split into K equal groups.  If $k = 5$ a 5-fold cross validation can be performed such that the data is split into $k_1$, $k_2$, $k_3$, $k_4$ and $k_5$. The model is trained on $k_2 - k_5$ and evaluated on $k_1$ then repeated $k$ times until every group is used to train and test the model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](datasets/images/kfold.png \"kfold.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.35714285714286,\n",
       " 50.90909090909091,\n",
       " 48.48484848484849,\n",
       " 58.119658119658126,\n",
       " 0.0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.split(normalised_train_df)\n",
    "f1_scores = []\n",
    "\n",
    "# run for every split\n",
    "for train_index, test_index in kf.split(normalised_train_df):\n",
    "    X_train_k, X_test_k = normalised_train_df.iloc[train_index], normalised_train_df.iloc[test_index]\n",
    "    y_train_k, y_test_k = y_balanced[train_index], y_balanced[test_index]\n",
    "    model = LogisticRegression().fit(X_train_k, y_train_k)\n",
    "    f1_scores.append(\n",
    "        f1_score(y_true=y_test_k, y_pred=model.predict(X_test_k), pos_label='2A')*100\n",
    "    )\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified K-Fold cross validation ensures that in every fold, there is an equal proportion of each target class to obtain a good representation of the data and avoid imbalance and biased results. For example, if there are two target classes $t_1$ and $t_2$ with equal distribution in the data, it is best to ensure that the folds also have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5714285714285714,\n",
       " 0.5742574257425743,\n",
       " 0.5242718446601942,\n",
       " 0.45161290322580644,\n",
       " 0.5263157894736842]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "f1_scores_skf = []\n",
    "for train_index, test_index in skf.split(normalised_train_df, y_balanced):\n",
    "    X_train_skf, X_test_skf = np.array(normalised_train_df)[train_index], np.array(normalised_train_df)[test_index]\n",
    "    y_train_skf, y_test_skf = y_balanced[train_index], y_balanced[test_index]\n",
    "    model = LogisticRegression().fit(X_train_skf, y_train_skf)\n",
    "    f1_scores_skf.append(\n",
    "        f1_score(y_true=y_test_skf, y_pred=model.predict(X_test_skf), pos_label='2A')\n",
    "    )\n",
    "f1_scores_skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Cross Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, one instance is left out and used as the test set while the model is trained on $N-1$ data points where $N$ is the number of data points. This means that the number of instances and folds are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532258064516129"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "scores_loo = cross_val_score(\n",
    "    LogisticRegression(), normalised_train_df, y_balanced, cv=loo, scoring='f1_macro'\n",
    ")\n",
    "average_score_loo = scores_loo.mean()\n",
    "average_score_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix, Precision-Recall, ROC curve and the F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, precision, recall, F1-score and many others are evaluation metrics used in measuring the performance of classification models. We will discuss these metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an $N$ x $N$ matrix that gives a summary of the correct and incorrect predicted classification results for the N target classes. The values in the diagonal of the matrix represent the number of correctly predicted classes while every other cell in the matrix indicates the misclassified classes. This means that the more predicted values that fall in the diagonal, the better the model. True positive, false positive, true negative and false negative are terms used when interpreting a confusion matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](datasets/images/confusion-matrix.png \"confusion-matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive (TP): \n",
    "This is a correct classification where the predicted value is the same as the actual value. Using the table above, this means that actual value was positive and the predicted value was also positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Negative (TN): \n",
    "The predicted value also matches the actual value. In this case, it is for the negative class. The actual value is negative and the predicted value is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive (FP): \n",
    "Also called a Type I error, this is a misclassification such that the model predicted a positive class while the actual class is negative. Telling a man that he is pregnant is definitely a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Negative (FN): \n",
    "Also another misclassification where the predicted value is negative and the actual value is positive. Another example will be telling a pregnant woman that she is not pregnant. FN is known as a Type II error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3A', '2A', '2A', '3A', '3A'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction = log_reg.predict(normalised_test_df)\n",
    "new_prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 42],\n",
       "       [55, 47]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=new_prediction, labels=['2A', '3A'])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the ratio of the number of correctly predicted instances to the total number of instances. It is a commonly used metric suitable when the target classes are not imbalanced. A high accuracy does not necessarily mean that the model has high predicting power. Hence, depending on the task, it is important to not use only the accuracy metric because it does not provide enough information about the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=new_prediction)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of correctly predicted instances of a class to the total number of items predicted by the model to be in that class is referred to as precision (known as Positive Predicted Value - PPV). This translates to the total percentage of the results obtained that are relevant. For the positive class, it is the ratio of true positives to the sum of true positives and false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.38\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=new_prediction, pos_label='2A')\n",
    "print(f'precision: {precision:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known as the sensitivity of the model, recall gives a percentage of total relevant results correctly predicted by the model. It is the ratio of the true positives to the actual number of positives (true positives and false negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is also a trade-off between precision and recall. It is impossible to maximise both metrics simultaneously because an increase in recall decreases precision. Identify which metric is important based on your task and optimise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.44\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_true=y_test, y_pred=new_prediction, pos_label='2A')\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric is the harmonic mean of precision and recall that aims to have an optimal balance of both. The F1-Score is quite easy to use and can be focused on to maximize as opposed to maximizing precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "F_1 = 2 * \\frac{precision * recall}{precision + recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.40\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=new_prediction, pos_label='2A')\n",
    "print(f\"F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Receiver Operating Characteristics (ROC) curve is a probability curve that measures the performance of a classification model at different set thresholds. Recall also known as the True Positive Rate (TPR) is plotted on the y-axis against the False Positive Rate (FPR) on the x-axis.\n",
    "\n",
    "The code examples above are not the optimal results that can be obtained with the model. Hyperparameter tuning can be performed to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
